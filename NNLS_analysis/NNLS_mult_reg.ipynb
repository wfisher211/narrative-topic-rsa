{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re, csv\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import statsmodels.api as sm\n",
    "from nilearn import datasets\n",
    "from nilearn.image import resample_to_img\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_1samp\n",
    "from nilearn import plotting, datasets\n",
    "import scipy.stats as stats\n",
    "from scipy.optimize import nnls   \n",
    "from statsmodels.stats.multitest import fdrcorrection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET MAIN HYPERPARAMETERS\n",
    "# TRAIT_LABEL = \"Contemplating\"  \n",
    "\n",
    "TRAIT_SETS = {\n",
    "    \"all_13\": [\n",
    "        \"Open-minded\",\"feeling Affectionate\",\"Attentive\",\"Assertive\",\n",
    "        \"feeling Gloomy\",\"feeling Peaceful\",\"Agreeable\",\"Judging\",\n",
    "        \"feeling Angry\",\"feeling Bewildered\",\"Impulsive\",\n",
    "        \"Self-disciplined\",\"Contemplating\"\n",
    "    ],\n",
    "    \"mental_8\": [\n",
    "        \"feeling Affectionate\",\"feeling Gloomy\",\"feeling Peaceful\",\n",
    "        \"feeling Angry\",\"feeling Bewildered\",\"Judging\",\n",
    "        \"Contemplating\",\"Attentive\"\n",
    "    ],\n",
    "    \"personality_5\": [\n",
    "        \"Open-minded\",\"Agreeable\",\"Assertive\",\n",
    "        \"Self-disciplined\",\"Impulsive\"\n",
    "    ],\n",
    "    \"trait_9\": [\n",
    "        \"Open-minded\",\"feeling Affectionate\",\"Attentive\",\"Assertive\",\n",
    "        \"Agreeable\",\"Judging\",\"feeling Angry\",\"Self-disciplined\",\"Contemplating\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Select model here: choose one key from TRAIT_SETS\n",
    "model_key = \"trait_9\"   # options: all_13, mental_8, personality_5, trait_9\n",
    "traits    = TRAIT_SETS[model_key]\n",
    "\n",
    "# ALL_TRAIT_LABELS = [\n",
    "    #\"Open-minded\",\"feeling Affectionate\",\"Attentive\",\"Assertive\",\n",
    "    #\"feeling Gloomy\",\"feeling Peaceful\",\"Agreeable\",\"Judging\",\n",
    "    #\"feeling Angry\",\"feeling Bewildered\",\"Impulsive\",\n",
    "    #\"Self-disciplined\",\"Contemplating\"\n",
    "#]\n",
    "ALL_TRAIT_SAVE_STRS = [t.replace(\" \",\"_\").replace(\"-\",\"_\")\n",
    "                       for t in traits]\n",
    "# Our 13 trait labels \n",
    "# [\"Open-minded\", \"feeling Affectionate\", \"Attentive\", \"Assertive\", \"feeling Gloomy\", \"feeling Peaceful\", \"Agreeable\", \"Judging\", \"feeling Angry\", \"feeling Bewildered\", \"Impulsive\", \"Self-disciplined\", \"Contemplating\"]\n",
    "\n",
    "#TRAIT_LABEL_SAVE_STRING = TRAIT_LABEL.replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "STIMULUS_LABEL_SAVE_STRING = \"reachforstars\"\n",
    "\n",
    "# Set smoothing setting to either use smoothed trait RDMs or the un-smoothed RDMs\n",
    "smoothing_setting = \"_no_smoothing\"    # set to _no_smoothing or set to \"\" for smoothed RDMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 0) PATHS & I/O\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "root_dir  = \"/Volumes/Passport/fmriprep\"          # ‚Üê  same as in cleaning script\n",
    "deriv_dir = os.path.join(root_dir, \"derivatives\") #   (don‚Äôt hard-code ‚Äúsubjects‚Äù yet)\n",
    "\n",
    "\n",
    "\n",
    "# output from your behaviour-model RSA\n",
    "for trait_long, trait_save in zip(traits, ALL_TRAIT_SAVE_STRS):\n",
    "    rdm_path = os.path.join(\n",
    "        deriv_dir, \"RDMs_behavior\",\n",
    "        f\"{STIMULUS_LABEL_SAVE_STRING}_{trait_save}_RDM{smoothing_setting}.npy\"\n",
    "    )\n",
    "    model_rdm = np.load(rdm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 1) SUBJECT / RUN FILTERS    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "exclude_subs = []\n",
    "exclude_sub_runs = []\n",
    "\n",
    "target_subject = None     # e.g. \"sub-002\" to run a single person\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using subject: sub-016\n",
      "Voxel size (mm): (3.0, 3.0, 4.0)\n",
      "TR (s): 1.5\n",
      "Shape: (65, 77, 49, 160)\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ find a subject that has a cleaned BOLD file ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "cleaned_root = os.path.join(\n",
    "    deriv_dir, f\"{STIMULUS_LABEL_SAVE_STRING}_cleaned\"\n",
    ")\n",
    "\n",
    "# build a sorted list of candidate subjects, excluding any in exclude_subs\n",
    "candidates = sorted(\n",
    "    s for s in os.listdir(cleaned_root)\n",
    "    if s.startswith(\"sub-\") and s not in exclude_subs\n",
    ")\n",
    "\n",
    "bold_img_path = None\n",
    "bold_sub      = None\n",
    "\n",
    "for sub in candidates:\n",
    "    func_dir = os.path.join(cleaned_root, sub, \"func\")\n",
    "\n",
    "    # (a) single‚Äêrun file\n",
    "    single_pattern = os.path.join(\n",
    "        func_dir,\n",
    "        f\"{sub}_task-{STIMULUS_LABEL_SAVE_STRING}_cleaned_desc-masked_bold.nii.gz\"\n",
    "    )\n",
    "    # (b) multi-run files (_run-01_, _run-02_, ‚Ä¶)\n",
    "    multi_pattern  = os.path.join(\n",
    "        func_dir,\n",
    "        f\"{sub}_task-{STIMULUS_LABEL_SAVE_STRING}_run-*_cleaned_desc-masked_bold.nii.gz\"\n",
    "    )\n",
    "\n",
    "    hits = glob.glob(single_pattern) or glob.glob(multi_pattern)\n",
    "    if hits:                         # found at least one file ‚Üí stop searching\n",
    "        bold_img_path = hits[0]      # take the first match\n",
    "        bold_sub      = sub\n",
    "        break\n",
    "\n",
    "if bold_img_path is None:\n",
    "    raise RuntimeError(\n",
    "        f\"No cleaned BOLD files found for stimulus '{STIMULUS_LABEL_SAVE_STRING}'.\"\n",
    "    )\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ load the image and report dimensions ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "bold_img = nib.load(bold_img_path)\n",
    "zooms    = bold_img.header.get_zooms()\n",
    "\n",
    "print(f\"Using subject: {bold_sub}\")\n",
    "print(f\"Voxel size (mm): {zooms[:3]}\")\n",
    "print(f\"TR (s): {zooms[3]}\")\n",
    "print(f\"Shape: {bold_img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects to process ‚Üí sub-016, sub-084, sub-106, sub-111, sub-132, sub-133, sub-134, sub-135, sub-136, sub-137, sub-138, sub-140, sub-141, sub-142, sub-143, sub-144, sub-145\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# 2)  BUILD SUBJECT LIST  (from cleaned derivatives)  ------------\n",
    "# ----------------------------------------------------------------\n",
    "cleaned_root = os.path.join(deriv_dir, f\"{STIMULUS_LABEL_SAVE_STRING}_cleaned\")\n",
    "all_subs     = sorted(\n",
    "    d for d in os.listdir(cleaned_root) if d.startswith(\"sub-\")\n",
    ")\n",
    "if target_subject:\n",
    "    if target_subject not in all_subs:\n",
    "        raise ValueError(f\"{target_subject} not found in {cleaned_root}\")\n",
    "    subjects = [target_subject]\n",
    "else:\n",
    "    subjects = [s for s in all_subs if s not in exclude_subs]\n",
    "\n",
    "print(\"Subjects to process ‚Üí\", \", \".join(subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# 3) FETCH SCHAEFER ATLAS  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# Schaefer parcel/atlas parameters\n",
    "n_rois = 200\n",
    "yeo_networks = 17\n",
    "resolution_mm = 2                   # resolution of your Schaefer atlas (double check!)\n",
    "\n",
    "schaefer    = datasets.fetch_atlas_schaefer_2018(\n",
    "                 n_rois=n_rois,\n",
    "                 yeo_networks=yeo_networks,\n",
    "                 resolution_mm=resolution_mm\n",
    "             )\n",
    "atlas_img   = nib.load(schaefer['maps'])  # default 2mm MNI - but our images 3x3x4 (Pieman and others) OR 2.5^3 (ie., Black and Forgot)\n",
    "\n",
    "atlas_resampled = resample_to_img(atlas_img, bold_img, interpolation='nearest')\n",
    "atlas_data     = atlas_resampled.get_fdata()\n",
    "\n",
    "\n",
    "\n",
    "# Change Schaeffer Labels so 0 is whole brain and 1 corresponds to 1st ROI\n",
    "labels = schaefer['labels']\n",
    "# change to string and remove excess\n",
    "labels = [l.replace(b'17Networks_', b'').decode('utf-8') for l in labels]\n",
    "# Prepend background label\n",
    "labels = np.insert(labels, 0, \"Background\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_r2(X, y):\n",
    "    \"\"\"\n",
    "    Compute the coefficient of determination (R¬≤) for a linear regression model.\n",
    "    Parameters\n",
    "    ----------\"\"\"\n",
    "    betas, _ = nnls(X, y)\n",
    "    y_pred = X @ betas\n",
    "    ss_res = np.sum((y - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return r2\n",
    "\n",
    "def permutation_test(X, y, n_permutations=10):\n",
    "\n",
    "    # compute observed R2\n",
    "    r2_observed = compute_r2(X, y)\n",
    "    \n",
    "    # Permutation test for R¬≤ - create null distribution from N permutations\n",
    "    r2_values = np.zeros(n_permutations)\n",
    "    for i in range(n_permutations):\n",
    "        y_permuted = np.random.permutation(y)\n",
    "        r2_values[i] = compute_r2(X, y_permuted)\n",
    "    \n",
    "\n",
    "    # retrurn p-value and pseudo-t value\n",
    "    pseudo_t = (r2_observed - np.mean(r2_values)) / np.std(r2_values, ddof=1)\n",
    "    p_value = np.mean(r2_values >= r2_observed)\n",
    "    return pseudo_t, p_value    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1) Load all the single-trait .npy RDMs \n",
    "model_rdms = {}\n",
    "for trait, sstr in zip(traits, ALL_TRAIT_SAVE_STRS):\n",
    "    filepath = os.path.join(\n",
    "        deriv_dir, \"RDMs_behavior\",\n",
    "        f\"{STIMULUS_LABEL_SAVE_STRING}_{sstr}_RDM{smoothing_setting}.npy\"\n",
    "    )\n",
    "    model_rdms[trait] = np.load(filepath)\n",
    "\n",
    "# 2) multi-regression RSA \n",
    "def rsa_multi_nnls(neural_rdm, model_rdms, traits):\n",
    "    idx = np.tril_indices(neural_rdm.shape[0], k=-1)\n",
    "    y   = neural_rdm[idx]\n",
    "    \n",
    "    # design matrix of all behavioural RDMs\n",
    "    Xs  = [model_rdms[t][idx] for t in traits]\n",
    "    X   = np.column_stack(Xs)              # shape (N, p)\n",
    "    X   = np.column_stack([np.ones_like(y), X])   # prepend intercept\n",
    "\n",
    "    # NNLS\n",
    "    coef, rnorm = nnls(X, y)                   \n",
    "    #coef, _ = nnls(X, y)                   # coef[0] = intercept\n",
    "    betas = dict(zip(traits, coef[1:]))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # pseudo-r2 for full model vs null (yÃÖ)\n",
    "    y_pred = X @ coef\n",
    "    ss_res = np.sum((y - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "\n",
    "    # compute pseudo F-statistic\n",
    "    p = len(traits) \n",
    "    N = len(y)\n",
    "    ss_reg = ss_tot - ss_res\n",
    "    f_stat = (ss_reg / p) / (ss_res / (N - p - 1))\n",
    "\n",
    "    \n",
    "    # permutation test\n",
    "    pseudo_t, permutation_p_value = permutation_test(X, y)\n",
    "\n",
    "    return betas, r2, pseudo_t, permutation_p_value, float(f_stat)\n",
    "\n",
    "# 3) run multi-regression for each subject \n",
    "def run_multi_for_subject(sub):\n",
    "    func_dir   = os.path.join(cleaned_root, sub, \"func\")\n",
    "    run_pat    = os.path.join(\n",
    "        func_dir,\n",
    "        f\"{sub}_task-{STIMULUS_LABEL_SAVE_STRING}_run-*_*cleaned_desc-masked_bold.nii.gz\"\n",
    "    )\n",
    "    single_pat = os.path.join(\n",
    "        func_dir,\n",
    "        f\"{sub}_task-{STIMULUS_LABEL_SAVE_STRING}_cleaned_desc-masked_bold.nii.gz\"\n",
    "    )\n",
    "    bold_files = sorted(glob.glob(run_pat)) + sorted(glob.glob(single_pat))\n",
    "    if not bold_files:\n",
    "        print(f\"‚è© {sub}: no runs\"); return\n",
    "\n",
    "    rows = []\n",
    "    for bf in bold_files:\n",
    "        m   = re.search(r\"_run-(\\d+)_\", os.path.basename(bf))\n",
    "        run = m.group(1) if m else \"NA\"\n",
    "        if (sub, run) in exclude_sub_runs: continue\n",
    "\n",
    "        bold_img  = nib.load(bf)\n",
    "        bold_data = bold_img.get_fdata()\n",
    "        atlas_res = resample_to_img(atlas_img, bold_img, interpolation=\"nearest\")\n",
    "        atlas_dat = atlas_res.get_fdata()\n",
    "\n",
    "        for parcel_id in range(1, n_rois+1):   \n",
    "            mask = atlas_dat == parcel_id\n",
    "            if not mask.any(): continue\n",
    "            neural_rdm = 1 - np.corrcoef(bold_data[mask,:].T).astype(np.float32)\n",
    "            betas, r2, pseudo_t, permutation_p_value, f_stat = rsa_multi_nnls(neural_rdm, model_rdms, traits)\n",
    "            parcel_label = labels[parcel_id]     # ‚Üê NEW column\n",
    "            # build row: sub, run, parcel, Œ≤‚ÇÅ‚Ä¶Œ≤‚ÇÅ‚ÇÉ, F_stat\n",
    "            row = [sub, run, parcel_id, parcel_label] + [betas[t] for t in traits] + [r2] + [pseudo_t] + [permutation_p_value]+[float(f_stat)]\n",
    "            rows.append(row)\n",
    "\n",
    "    # write out into a new multi_regression folder\n",
    "    out_base = os.path.join(\n",
    "        deriv_dir, \"RSA_stats\",\n",
    "        STIMULUS_LABEL_SAVE_STRING, \"multi_regression\", \"subject_results\"\n",
    "    )\n",
    "    os.makedirs(out_base, exist_ok=True)\n",
    "\n",
    "    header = [\"subject\",\"run\",\"parcel_num\", \"parcel_label\"] + ALL_TRAIT_SAVE_STRS + [\"r2\"] + [\"pseudo_t\"] + [\"permutation_p_value\"]+[\"f_stat\"]\n",
    "    out_csv = os.path.join(\n",
    "        out_base,\n",
    "        f\"{sub}_{STIMULUS_LABEL_SAVE_STRING}_multi_parcel_RSA_NNLS_{model_key}{smoothing_setting}.csv\"\n",
    "    )\n",
    "    with open(out_csv, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(header)\n",
    "        w.writerows(rows)\n",
    "\n",
    "    print(f\"‚úÖ {sub} MULTI-REG CSV ‚Üí {out_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ sub-016 MULTI-REG CSV ‚Üí /Volumes/Passport/fmriprep/derivatives/RSA_stats/reachforstars/multi_regression/subject_results/sub-016_reachforstars_multi_parcel_RSA_NNLS_trait_9_no_smoothing.csv\n",
      "‚úÖ sub-084 MULTI-REG CSV ‚Üí /Volumes/Passport/fmriprep/derivatives/RSA_stats/reachforstars/multi_regression/subject_results/sub-084_reachforstars_multi_parcel_RSA_NNLS_trait_9_no_smoothing.csv\n",
      "‚úÖ sub-106 MULTI-REG CSV ‚Üí /Volumes/Passport/fmriprep/derivatives/RSA_stats/reachforstars/multi_regression/subject_results/sub-106_reachforstars_multi_parcel_RSA_NNLS_trait_9_no_smoothing.csv\n",
      "‚úÖ sub-111 MULTI-REG CSV ‚Üí /Volumes/Passport/fmriprep/derivatives/RSA_stats/reachforstars/multi_regression/subject_results/sub-111_reachforstars_multi_parcel_RSA_NNLS_trait_9_no_smoothing.csv\n",
      "‚úÖ sub-132 MULTI-REG CSV ‚Üí /Volumes/Passport/fmriprep/derivatives/RSA_stats/reachforstars/multi_regression/subject_results/sub-132_reachforstars_multi_parcel_RSA_NNLS_trait_9_no_smoothing.csv\n",
      "‚úÖ sub-133 MULTI-REG CSV ‚Üí /Volumes/Passport/fmriprep/derivatives/RSA_stats/reachforstars/multi_regression/subject_results/sub-133_reachforstars_multi_parcel_RSA_NNLS_trait_9_no_smoothing.csv\n",
      "‚úÖ sub-134 MULTI-REG CSV ‚Üí /Volumes/Passport/fmriprep/derivatives/RSA_stats/reachforstars/multi_regression/subject_results/sub-134_reachforstars_multi_parcel_RSA_NNLS_trait_9_no_smoothing.csv\n",
      "‚úÖ sub-135 MULTI-REG CSV ‚Üí /Volumes/Passport/fmriprep/derivatives/RSA_stats/reachforstars/multi_regression/subject_results/sub-135_reachforstars_multi_parcel_RSA_NNLS_trait_9_no_smoothing.csv\n",
      "‚úÖ sub-136 MULTI-REG CSV ‚Üí /Volumes/Passport/fmriprep/derivatives/RSA_stats/reachforstars/multi_regression/subject_results/sub-136_reachforstars_multi_parcel_RSA_NNLS_trait_9_no_smoothing.csv\n",
      "‚úÖ sub-137 MULTI-REG CSV ‚Üí /Volumes/Passport/fmriprep/derivatives/RSA_stats/reachforstars/multi_regression/subject_results/sub-137_reachforstars_multi_parcel_RSA_NNLS_trait_9_no_smoothing.csv\n",
      "‚úÖ sub-138 MULTI-REG CSV ‚Üí /Volumes/Passport/fmriprep/derivatives/RSA_stats/reachforstars/multi_regression/subject_results/sub-138_reachforstars_multi_parcel_RSA_NNLS_trait_9_no_smoothing.csv\n",
      "‚úÖ sub-140 MULTI-REG CSV ‚Üí /Volumes/Passport/fmriprep/derivatives/RSA_stats/reachforstars/multi_regression/subject_results/sub-140_reachforstars_multi_parcel_RSA_NNLS_trait_9_no_smoothing.csv\n",
      "‚úÖ sub-141 MULTI-REG CSV ‚Üí /Volumes/Passport/fmriprep/derivatives/RSA_stats/reachforstars/multi_regression/subject_results/sub-141_reachforstars_multi_parcel_RSA_NNLS_trait_9_no_smoothing.csv\n",
      "‚úÖ sub-142 MULTI-REG CSV ‚Üí /Volumes/Passport/fmriprep/derivatives/RSA_stats/reachforstars/multi_regression/subject_results/sub-142_reachforstars_multi_parcel_RSA_NNLS_trait_9_no_smoothing.csv\n",
      "‚úÖ sub-143 MULTI-REG CSV ‚Üí /Volumes/Passport/fmriprep/derivatives/RSA_stats/reachforstars/multi_regression/subject_results/sub-143_reachforstars_multi_parcel_RSA_NNLS_trait_9_no_smoothing.csv\n",
      "‚úÖ sub-144 MULTI-REG CSV ‚Üí /Volumes/Passport/fmriprep/derivatives/RSA_stats/reachforstars/multi_regression/subject_results/sub-144_reachforstars_multi_parcel_RSA_NNLS_trait_9_no_smoothing.csv\n",
      "‚úÖ sub-145 MULTI-REG CSV ‚Üí /Volumes/Passport/fmriprep/derivatives/RSA_stats/reachforstars/multi_regression/subject_results/sub-145_reachforstars_multi_parcel_RSA_NNLS_trait_9_no_smoothing.csv\n",
      "ALL MULTI-REG DONE üéâ\n"
     ]
    }
   ],
   "source": [
    "# 4) callfor each subject\n",
    "for sub in subjects:\n",
    "    run_multi_for_subject(sub)\n",
    "    # break             # comment out to run all subjects\n",
    "\n",
    "print(\"ALL MULTI-REG DONE üéâ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask saved ‚Üí parcel_173_mask.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from nilearn.image import resample_to_img\n",
    "\n",
    "# atlases you already loaded\n",
    "atlas_res = resample_to_img(atlas_img, bold_img, interpolation=\"nearest\")\n",
    "atlas_data = atlas_res.get_fdata()\n",
    "\n",
    "parcel_id = 173            # pick any ID you want to sanity-check\n",
    "mask      = (atlas_data == parcel_id).astype(np.uint8)\n",
    "\n",
    "mask_img = nib.Nifti1Image(mask, atlas_res.affine, atlas_res.header)\n",
    "nib.save(mask_img, f\"parcel_{parcel_id}_mask.nii.gz\")\n",
    "print(\"mask saved ‚Üí parcel_173_mask.nii.gz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
