{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, re, csv\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import statsmodels.api as sm\n",
    "from nilearn import datasets\n",
    "from nilearn.image import resample_to_img\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_1samp\n",
    "from nilearn import plotting, datasets\n",
    "import scipy.stats as stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel size (mm): (3.0, 3.0, 4.0)\n",
      "TR (s): 1.0\n",
      "Shape (65, 77, 49, 160)\n"
     ]
    }
   ],
   "source": [
    "# Load the BOLD cleaned image\n",
    "bold_img = nib.load('/Volumes/Passport/fmriprep/derivatives/pieMan_cleaned/sub-002/func/sub-002_task-pieman_run-1_cleaned_desc-masked_bold.nii.gz')\n",
    "\n",
    "# Print voxel size (spatial resolution) and TR (temporal resolution)\n",
    "zooms = bold_img.header.get_zooms()\n",
    "print(f\"Voxel size (mm): {zooms[:3]}\")\n",
    "print(f\"TR (s): {zooms[3]}\")\n",
    "print(f\"Shape {bold_img.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET MAIN HYPERPARAMETERS\n",
    "TRAIT_LABEL = \"Contemplating\"  \n",
    "\n",
    "# Our 13 trait labels \n",
    "# [\"Open-minded\", \"feeling Affectionate\", \"Attentive\", \"Assertive\", \"feeling Gloomy\", \"feeling Peaceful\", \"Agreeable\", \"Judging\", \"feeling Angry\", \"feeling Bewildered\", \"Impulsive\", \"Self-disciplined\", \"Contemplating\"]\n",
    "\n",
    "TRAIT_LABEL_SAVE_STRING = TRAIT_LABEL.replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "STIMULUS_LABEL_SAVE_STRING = \"pieman\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# 0) PATHS & I/O\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "root_dir  = \"/Volumes/Passport/fmriprep\"          # ←  same as in cleaning script\n",
    "deriv_dir = os.path.join(root_dir, \"derivatives\") #   (don’t hard-code “subjects” yet)\n",
    "\n",
    "\n",
    "\n",
    "# output from your behaviour-model RSA\n",
    "model_rdm = np.load(\n",
    "    os.path.join(deriv_dir, \"RDMs_behavior\", f\"{STIMULUS_LABEL_SAVE_STRING}_{TRAIT_LABEL_SAVE_STRING}_RDM.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# 1) SUBJECT / RUN FILTERS  (copy-paste verbatim)  ─────────────\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "exclude_subs = {\n",
    "    \"sub-001\",\"sub-021\",\"sub-022\",\"sub-038\",\"sub-056\",\"sub-068\",\"sub-069\"\n",
    "}\n",
    "exclude_sub_runs = {\n",
    "    (\"sub-002\",\"2\"),(\"sub-003\",\"2\"),(\"sub-004\",\"2\"),(\"sub-005\",\"2\"),(\"sub-006\",\"2\"),\n",
    "    (\"sub-008\",\"2\"),(\"sub-010\",\"2\"),(\"sub-011\",\"2\"),(\"sub-012\",\"2\"),(\"sub-013\",\"2\"),\n",
    "    (\"sub-014\",\"2\"),(\"sub-015\",\"2\"),(\"sub-016\",\"2\")\n",
    "}\n",
    "target_subject = None     # e.g. \"sub-002\" to run a single person\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects to process → sub-002, sub-003, sub-004, sub-005, sub-006, sub-007, sub-008, sub-009, sub-010, sub-011, sub-012, sub-013, sub-014, sub-015, sub-016, sub-017, sub-018, sub-019, sub-020, sub-023, sub-024, sub-025, sub-026, sub-027, sub-028, sub-029, sub-030, sub-031, sub-032, sub-033, sub-034, sub-035, sub-036, sub-037, sub-039, sub-040, sub-041, sub-042, sub-043, sub-044, sub-045, sub-046, sub-047, sub-048, sub-049, sub-050, sub-051, sub-052, sub-053, sub-054, sub-055, sub-057, sub-058, sub-059, sub-060, sub-061, sub-062, sub-063, sub-064, sub-065, sub-066, sub-067, sub-070, sub-071, sub-072, sub-073, sub-074, sub-075, sub-076, sub-077, sub-078, sub-079, sub-080, sub-081, sub-082\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------\n",
    "# 2)  BUILD SUBJECT LIST  (from cleaned derivatives)  ------------\n",
    "# ----------------------------------------------------------------\n",
    "cleaned_root = os.path.join(deriv_dir, f\"{STIMULUS_LABEL_SAVE_STRING}_cleaned\")\n",
    "all_subs     = sorted(\n",
    "    d for d in os.listdir(cleaned_root) if d.startswith(\"sub-\")\n",
    ")\n",
    "if target_subject:\n",
    "    if target_subject not in all_subs:\n",
    "        raise ValueError(f\"{target_subject} not found in {cleaned_root}\")\n",
    "    subjects = [target_subject]\n",
    "else:\n",
    "    subjects = [s for s in all_subs if s not in exclude_subs]\n",
    "\n",
    "print(\"Subjects to process →\", \", \".join(subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# 3) FETCH SCHAEFER ATLAS  ─────────────────────────────────────\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "# Schaefer parcel/atlas parameters\n",
    "n_rois = 200\n",
    "yeo_networks = 17\n",
    "resolution_mm = 2                   # resolution of your Schaefer atlas (double check!)\n",
    "\n",
    "schaefer    = datasets.fetch_atlas_schaefer_2018(\n",
    "                 n_rois=n_rois,\n",
    "                 yeo_networks=yeo_networks,\n",
    "                 resolution_mm=resolution_mm\n",
    "             )\n",
    "atlas_img   = nib.load(schaefer['maps'])  # default 2mm MNI - but our images 3x3x4 (Pieman and others) OR 2.5^3 (ie., Black and Forgot)\n",
    "\n",
    "atlas_resampled = resample_to_img(atlas_img, bold_img, interpolation='nearest')\n",
    "atlas_data     = atlas_resampled.get_fdata()\n",
    "\n",
    "\n",
    "\n",
    "# Change Schaeffer Labels so 0 is whole brain and 1 corresponds to 1st ROI\n",
    "labels = schaefer['labels']\n",
    "# change to string and remove excess\n",
    "labels = [l.replace(b'17Networks_', b'').decode('utf-8') for l in labels]\n",
    "# Prepend background label\n",
    "labels = np.insert(labels, 0, \"Background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# 4) Define OLS function  ─────────────────────────────────────\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "def rsa_ols(neural_rdm: np.ndarray, model_rdm: np.ndarray):\n",
    "    \"\"\"OLS RSA identical in logic and naming to the manual example.\"\"\"\n",
    "    # ------------------------------------------------------------------\n",
    "    # EXTRACT ONE TRIANGLE (lower inc. diagonal)            ↳ k = -1\n",
    "    # ------------------------------------------------------------------\n",
    "    i_low = np.tril_indices(160, k=-1)\n",
    "\n",
    "    y = neural_rdm[i_low]                         # dependent variable\n",
    "    X = model_rdm[i_low][:, None]      # predictor (N × 1)\n",
    "    X = sm.add_constant(X)  # add intercept column\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # OLS FIT (statsmodels)                                         \n",
    "    # ------------------------------------------------------------------\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    beta = float(model.params[1])                 # coefficient for x1\n",
    "    r2   = float(model.rsquared)\n",
    "    return beta, r2\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 5) Define MAIN per-subject function  (adds run-skip check)  ─────────\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "def run_parcel_rsa_for_subject(sub):\n",
    "    func_dir   = os.path.join(cleaned_root, sub, \"func\")\n",
    "    run_pat    = os.path.join(func_dir,\n",
    "                  f\"{sub}_task-{STIMULUS_LABEL_SAVE_STRING}_run-*_*cleaned_desc-masked_bold.nii.gz\")\n",
    "    single_pat = os.path.join(func_dir,\n",
    "                  f\"{sub}_task-{STIMULUS_LABEL_SAVE_STRING}_cleaned_desc-masked_bold.nii.gz\")\n",
    "    bold_files = sorted(glob.glob(run_pat)) + sorted(glob.glob(single_pat))\n",
    "    if not bold_files:\n",
    "        print(f\"⏩ {sub}: no cleaned runs\")\n",
    "        return\n",
    "\n",
    "    rows = []\n",
    "    for bf in bold_files:\n",
    "        m   = re.search(r\"_run-(\\d+)_\", os.path.basename(bf))\n",
    "        run = m.group(1) if m else None\n",
    "        if run and (sub, run) in exclude_sub_runs:\n",
    "            print(f\"   • skipping {sub} run-{run} (in exclusion list)\")\n",
    "            continue\n",
    "\n",
    "        bold_img  = nib.load(bf)\n",
    "        bold_data = bold_img.get_fdata()\n",
    "\n",
    "        atlas_resampled = resample_to_img(atlas_img, bold_img, interpolation=\"nearest\")\n",
    "        atlas_data      = atlas_resampled.get_fdata()\n",
    "\n",
    "        for parcel_id in range(1, n_rois + 1):\n",
    "            mask = atlas_data == parcel_id\n",
    "            if not mask.any(): continue\n",
    "            rdm   = 1 - np.corrcoef(bold_data[mask, :].T).astype(np.float32)\n",
    "            beta, r2 = rsa_ols(rdm, model_rdm)\n",
    "            parcel_label = labels[parcel_id]\n",
    "            rows.append([sub, run or \"NA\", parcel_id, parcel_label, beta, r2])\n",
    "            \n",
    "    # ---- write one CSV per subject ----\n",
    "    out_dir  = os.path.join(deriv_dir, \"RSA_stats\")\n",
    "\n",
    "    # add the stimulus‐specific subfolder (e.g. \"pieman\")\n",
    "    stim_folder = os.path.join(out_dir, STIMULUS_LABEL_SAVE_STRING)\n",
    "    os.makedirs(stim_folder, exist_ok=True)\n",
    "\n",
    "    # add the trait‐specific subfolder (e.g. \"feeling_Affectionate\")\n",
    "    trait_folder = os.path.join(stim_folder, TRAIT_LABEL_SAVE_STRING)\n",
    "    os.makedirs(trait_folder, exist_ok=True)\n",
    "\n",
    "    out_csv = os.path.join(trait_folder, f\"{sub}_{STIMULUS_LABEL_SAVE_STRING}_{TRAIT_LABEL_SAVE_STRING}_parcel_RSA.csv\")\n",
    "    with open(out_csv, \"w\", newline=\"\") as f:\n",
    "        csv.writer(f).writerows([[\"subject\",\"run\",\"parcel_num\",\"parcel_label\",\"beta\",\"r2\"]] + rows)\n",
    "    print(f\"✅ {sub}: {len(rows)} rows → {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ sub-002: 200 rows → /Volumes/Passport/fmriprep/derivatives/RSA_stats/pieman/Contemplating/sub-002_pieman_Contemplating_parcel_RSA.csv\n",
      "✅ sub-003: 200 rows → /Volumes/Passport/fmriprep/derivatives/RSA_stats/pieman/Contemplating/sub-003_pieman_Contemplating_parcel_RSA.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 6. CALL FUNCTION FOR EACH SUBJECT\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sub \u001b[38;5;129;01min\u001b[39;00m subjects:\n\u001b[0;32m----> 5\u001b[0m     run_parcel_rsa_for_subject(sub)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mALL DONE 🎉\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[59], line 50\u001b[0m, in \u001b[0;36mrun_parcel_rsa_for_subject\u001b[0;34m(sub)\u001b[0m\n\u001b[1;32m     47\u001b[0m bold_img  \u001b[38;5;241m=\u001b[39m nib\u001b[38;5;241m.\u001b[39mload(bf)\n\u001b[1;32m     48\u001b[0m bold_data \u001b[38;5;241m=\u001b[39m bold_img\u001b[38;5;241m.\u001b[39mget_fdata()\n\u001b[0;32m---> 50\u001b[0m atlas_resampled \u001b[38;5;241m=\u001b[39m resample_to_img(atlas_img, bold_img, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m atlas_data      \u001b[38;5;241m=\u001b[39m atlas_resampled\u001b[38;5;241m.\u001b[39mget_fdata()\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m parcel_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_rois \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/nilearn/image/resampling.py:748\u001b[0m, in \u001b[0;36mresample_to_img\u001b[0;34m(source_img, target_img, interpolation, copy, order, clip, fill_value, force_resample)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresample_to_img\u001b[39m(\n\u001b[1;32m    688\u001b[0m     source_img,\n\u001b[1;32m    689\u001b[0m     target_img,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    695\u001b[0m     force_resample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    696\u001b[0m ):\n\u001b[1;32m    697\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resample a Niimg-like source image on a target Niimg-like image.\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \n\u001b[1;32m    699\u001b[0m \u001b[38;5;124;03m    No registration is performed: the image should already be aligned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    746\u001b[0m \n\u001b[1;32m    747\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 748\u001b[0m     target \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mcheck_niimg(target_img)\n\u001b[1;32m    749\u001b[0m     target_shape \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;66;03m# When target shape is greater than 3, we reduce to 3, to be compatible\u001b[39;00m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;66;03m# with underlying call to resample_img\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/nilearn/_utils/niimg_conversions.py:315\u001b[0m, in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ni\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mconcat_imgs(\n\u001b[1;32m    311\u001b[0m         niimg, ensure_ndim\u001b[38;5;241m=\u001b[39mensure_ndim, dtype\u001b[38;5;241m=\u001b[39mdtype\n\u001b[1;32m    312\u001b[0m     )\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m niimg \u001b[38;5;241m=\u001b[39m load_niimg(niimg, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_ndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(niimg\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m niimg\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# \"squeeze\" the image.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     data \u001b[38;5;241m=\u001b[39m safe_get_data(niimg)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/nilearn/_utils/niimg.py:135\u001b[0m, in \u001b[0;36mload_niimg\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(niimg, nibabel\u001b[38;5;241m.\u001b[39mspatialimages\u001b[38;5;241m.\u001b[39mSpatialImage):\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData given cannot be loaded because it is\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not compatible with nibabel format:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;241m+\u001b[39m _repr_niimgs(niimg, shorten\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    133\u001b[0m     )\n\u001b[0;32m--> 135\u001b[0m dtype \u001b[38;5;241m=\u001b[39m _get_target_dtype(_get_data(niimg)\u001b[38;5;241m.\u001b[39mdtype, dtype)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# Copyheader and set dtype in header if header exists\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m niimg\u001b[38;5;241m.\u001b[39mheader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/nilearn/_utils/niimg.py:25\u001b[0m, in \u001b[0;36m_get_data\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39m_data_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39m_data_cache\n\u001b[0;32m---> 25\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(img\u001b[38;5;241m.\u001b[39m_dataobj)\n\u001b[1;32m     26\u001b[0m img\u001b[38;5;241m.\u001b[39m_data_cache \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/nibabel/arrayproxy.py:454\u001b[0m, in \u001b[0;36mArrayProxy.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    434\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read data from file and apply scaling, casting to ``dtype``\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m    If ``dtype`` is unspecified, the dtype of the returned array is the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m        Scaled image data with type `dtype`.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_scaled(dtype\u001b[38;5;241m=\u001b[39mdtype, slicer\u001b[38;5;241m=\u001b[39m())\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    456\u001b[0m         arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/nibabel/arrayproxy.py:421\u001b[0m, in \u001b[0;36mArrayProxy._get_scaled\u001b[0;34m(self, dtype, slicer)\u001b[0m\n\u001b[1;32m    419\u001b[0m     scl_inter \u001b[38;5;241m=\u001b[39m scl_inter\u001b[38;5;241m.\u001b[39mastype(use_dtype)\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# Read array and upcast as necessary for big slopes, intercepts\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m scaled \u001b[38;5;241m=\u001b[39m apply_read_scaling(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_unscaled(slicer\u001b[38;5;241m=\u001b[39mslicer), scl_slope, scl_inter)\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    423\u001b[0m     scaled \u001b[38;5;241m=\u001b[39m scaled\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mpromote_types(scaled\u001b[38;5;241m.\u001b[39mdtype, dtype), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/nibabel/arrayproxy.py:391\u001b[0m, in \u001b[0;36mArrayProxy._get_unscaled\u001b[0;34m(self, slicer)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m canonical_slicers(slicer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m==\u001b[39m canonical_slicers(\n\u001b[1;32m    388\u001b[0m     (), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    389\u001b[0m ):\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m array_from_file(\n\u001b[1;32m    392\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape,\n\u001b[1;32m    393\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype,\n\u001b[1;32m    394\u001b[0m             fileobj,\n\u001b[1;32m    395\u001b[0m             offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset,\n\u001b[1;32m    396\u001b[0m             order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder,\n\u001b[1;32m    397\u001b[0m             mmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mmap,\n\u001b[1;32m    398\u001b[0m         )\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_fileobj() \u001b[38;5;28;01mas\u001b[39;00m fileobj:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fileslice(\n\u001b[1;32m    401\u001b[0m         fileobj,\n\u001b[1;32m    402\u001b[0m         slicer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m         lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock,\n\u001b[1;32m    408\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/nibabel/volumeutils.py:467\u001b[0m, in \u001b[0;36marray_from_file\u001b[0;34m(shape, in_dtype, infile, offset, order, mmap)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(infile, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreadinto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    466\u001b[0m     data_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(n_bytes)\n\u001b[0;32m--> 467\u001b[0m     n_read \u001b[38;5;241m=\u001b[39m infile\u001b[38;5;241m.\u001b[39mreadinto(data_bytes)\n\u001b[1;32m    468\u001b[0m     needs_copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/gzip.py:324\u001b[0m, in \u001b[0;36mGzipFile.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01merrno\u001b[39;00m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(errno\u001b[38;5;241m.\u001b[39mEBADF, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread() on write-only GzipFile object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mread(size)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[0;32m---> 68\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m(byte_view))\n\u001b[1;32m     69\u001b[0m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/gzip.py:535\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39mneeds_input:\n\u001b[1;32m    534\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(READ_BUFFER_SIZE)\n\u001b[0;32m--> 535\u001b[0m     uncompress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39mdecompress(buf, size)\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    537\u001b[0m     uncompress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39mdecompress(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# 6. CALL FUNCTION FOR EACH SUBJECT\n",
    "# ----------------------------------------------------------------------\n",
    "for sub in subjects:\n",
    "    run_parcel_rsa_for_subject(sub)\n",
    "\n",
    "print(\"\\nALL DONE 🎉\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parcel  ➜  026  (R² = 0.002368)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rsa_df = pd.read_csv(f'/Volumes/Passport/fmriprep/derivatives/RSA_stats/{STIMULUS_LABEL_SAVE_STRING}/{TRAIT_LABEL_SAVE_STRING}/sub-002_{STIMULUS_LABEL_SAVE_STRING}_{TRAIT_LABEL_SAVE_STRING}_parcel_RSA.csv')\n",
    "\n",
    "# identify parcel with max R²\n",
    "best_row = rsa_df.loc[rsa_df['r2'].idxmax()]\n",
    "best_parcel = int(best_row['parcel'])\n",
    "print(f\"Best parcel  ➜  {best_parcel:03d}  (R² = {best_row['r2']:.6f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     subject  run  parcel      beta        r2\n",
      "0    sub-002    1       1  0.002346  0.001399\n",
      "1    sub-002    1       2  0.001935  0.000508\n",
      "2    sub-002    1       3  0.002379  0.000734\n",
      "3    sub-002    1       4  0.002333  0.000706\n",
      "4    sub-002    1       5  0.001665  0.000607\n",
      "..       ...  ...     ...       ...       ...\n",
      "195  sub-002    1     196  0.001695  0.000855\n",
      "196  sub-002    1     197  0.001400  0.000621\n",
      "197  sub-002    1     198  0.001602  0.000647\n",
      "198  sub-002    1     199  0.002046  0.000974\n",
      "199  sub-002    1     200  0.002078  0.001124\n",
      "\n",
      "[200 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(rsa_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>run</th>\n",
       "      <th>parcel</th>\n",
       "      <th>beta</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>0.001399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>0.000508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.000734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.000607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>sub-082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196</td>\n",
       "      <td>-0.000262</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>sub-082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>sub-082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>sub-082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>199</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>sub-082</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.001124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject  run  parcel      beta        r2\n",
       "0      sub-002  1.0       1  0.002346  0.001399\n",
       "1      sub-002  1.0       2  0.001935  0.000508\n",
       "2      sub-002  1.0       3  0.002379  0.000734\n",
       "3      sub-002  1.0       4  0.002333  0.000706\n",
       "4      sub-002  1.0       5  0.001665  0.000607\n",
       "...        ...  ...     ...       ...       ...\n",
       "14995  sub-082  NaN     196 -0.000262  0.000070\n",
       "14996  sub-082  NaN     197 -0.000060  0.000003\n",
       "14997  sub-082  NaN     198  0.000255  0.000043\n",
       "14998  sub-082  NaN     199  0.000759  0.000340\n",
       "14999  sub-082  NaN     200  0.001267  0.001124\n",
       "\n",
       "[15000 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate all dfs from all subjects into 1 big df\n",
    "all_df = pd.DataFrame()\n",
    "\n",
    "for sub in subjects:\n",
    "    temp_df = pd.read_csv(f'/Volumes/Passport/fmriprep/derivatives/RSA_stats/{STIMULUS_LABEL_SAVE_STRING}/{TRAIT_LABEL_SAVE_STRING}/{sub}_{STIMULUS_LABEL_SAVE_STRING}_{TRAIT_LABEL_SAVE_STRING}_parcel_RSA.csv')\n",
    "    all_df = pd.concat([all_df, temp_df], ignore_index=True)\n",
    "\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.subject.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_values = []\n",
    "p_values = []\n",
    "\n",
    "for parcel in range(1,n_rois+1):\n",
    "    parcel_df = all_df[all_df['parcel'] == parcel]\n",
    "    assert len(parcel_df) == 75, f\"There should be 75 subjects data per parcel, there is only {len(parcel_df)}\"\n",
    "\n",
    "    # Perform t-test\n",
    "    t, p = ttest_1samp(parcel_df['beta'], 0, alternative='greater')\n",
    "    t_values.append(t)\n",
    "    p_values.append(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5812566776944334e-14"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(p_values)\n",
    "# np.min(t_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5268098454845155"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(t_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved group stats for Contemplating →\n",
      "   /Volumes/Passport/fmriprep/derivatives/RSA_stats/pieman/Contemplating/group_stats_pieman_Contemplating.csv\n"
     ]
    }
   ],
   "source": [
    "# 1) build a summary DataFrame\n",
    "summary_df = pd.DataFrame({\n",
    "    \"parcel_num\": np.arange(1, n_rois + 1),\n",
    "    \"parcel_label\": labels[1:],  # skip background label\n",
    "    \"t_value\": t_values,\n",
    "    \"p_value\": p_values\n",
    "})\n",
    "\n",
    "# 2) make sure the trait folder exists\n",
    "output_folder = os.path.join(\n",
    "    deriv_dir,\n",
    "    \"RSA_stats\",\n",
    "    STIMULUS_LABEL_SAVE_STRING,\n",
    "    TRAIT_LABEL_SAVE_STRING\n",
    ")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 3) write it out\n",
    "outfile = os.path.join(\n",
    "    output_folder,\n",
    "    f\"group_stats_{STIMULUS_LABEL_SAVE_STRING}_{TRAIT_LABEL_SAVE_STRING}.csv\"\n",
    ")\n",
    "summary_df.to_csv(outfile, index=False)\n",
    "\n",
    "print(f\"✅ Saved group stats for {TRAIT_LABEL} →\\n   {outfile}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
